/**
 * Model Research Platform Configuration
 * Top 100+ AI Models for WebLLM/WebGPU - Ranking by Innovation
 *
 * Categories:
 * - llm: Language Models for text generation
 * - vision: Vision/Image models
 * - audio: Speech/Audio models
 * - embedding: Embedding models for RAG/Search
 * - multimodal: Vision-Language models
 * - generation: Image/Audio generation
 */

export type ModelCategory = 'llm' | 'vision' | 'audio' | 'embedding' | 'multimodal' | 'generation';
export type ModelFramework = 'WebLLM' | 'Transformers.js' | 'ONNX Runtime Web';

export interface ModelConfig {
  id: string;
  name: string;
  rank: number;
  category: ModelCategory;
  size: string;
  vram: string;
  framework: ModelFramework;
  innovationScore: 1 | 2 | 3 | 4 | 5;
  description: string;
  whyTop: string;
  useCases: string[];
  codeExample: string;
  modelId: string; // For actual loading
  docsUrl?: string;
  demoType: 'text' | 'image' | 'audio' | 'embedding' | 'multimodal';
}

// Top 10 Models - Maximum Innovation
export const TOP_10_MODELS: ModelConfig[] = [
  {
    id: 'deepseek-r1-qwen',
    name: 'DeepSeek-R1-Distill-Qwen-1.5B',
    rank: 1,
    category: 'llm',
    size: '~1.5B par√°metros',
    vram: '~2GB (quantizado)',
    framework: 'Transformers.js',
    innovationScore: 5,
    description: 'Primer modelo de razonamiento avanzado "think step-by-step" que corre completamente en el navegador con WebGPU.',
    whyTop: 'Permite crear aplicaciones de resoluci√≥n de problemas complejos, tutores de matem√°ticas, y asistentes de c√≥digo que funcionan 100% offline. ~60 tokens/segundo.',
    useCases: ['Tutores de matem√°ticas', 'Asistentes de c√≥digo', 'Resoluci√≥n de problemas', 'Razonamiento l√≥gico'],
    codeExample: `import { pipeline } from "@huggingface/transformers";

const generator = await pipeline(
  "text-generation",
  "onnx-community/DeepSeek-R1-Distill-Qwen-1.5B",
  { device: "webgpu" }
);

const result = await generator(
  "Explain step by step how to solve: 2x + 5 = 13",
  { max_new_tokens: 200 }
);`,
    modelId: 'onnx-community/DeepSeek-R1-Distill-Qwen-1.5B',
    docsUrl: 'https://huggingface.co/onnx-community/DeepSeek-R1-Distill-Qwen-1.5B',
    demoType: 'text'
  },
  {
    id: 'smolvlm',
    name: 'SmolVLM (256M / 500M)',
    rank: 2,
    category: 'multimodal',
    size: '256M / 500M par√°metros',
    vram: '~500MB - 1GB',
    framework: 'Transformers.js',
    innovationScore: 5,
    description: 'El modelo multimodal m√°s peque√±o y eficiente para navegador. Analiza im√°genes en tiempo real.',
    whyTop: 'Permite crear apps que "ven" y describen im√°genes, hacen OCR, responden preguntas sobre fotos - todo sin enviar datos a servidores. Ideal para privacidad.',
    useCases: ['Descripci√≥n de im√°genes', 'OCR', 'Visual Q&A', 'Accesibilidad'],
    codeExample: `import { SmolVLMForConditionalGeneration } from "@huggingface/transformers";

const model = await SmolVLMForConditionalGeneration.from_pretrained(
  "onnx-community/SmolVLM-500M-Instruct",
  { dtype: "q4", device: "webgpu" }
);

// Analizar una imagen
const result = await model.generate({
  image: imageElement,
  prompt: "Describe what you see in this image"
});`,
    modelId: 'onnx-community/SmolVLM-500M-Instruct',
    docsUrl: 'https://huggingface.co/onnx-community/SmolVLM-500M-Instruct',
    demoType: 'multimodal'
  },
  {
    id: 'whisper',
    name: 'Whisper (tiny/base/small)',
    rank: 3,
    category: 'audio',
    size: '39M - 244M par√°metros',
    vram: '~150MB - 1GB',
    framework: 'Transformers.js',
    innovationScore: 5,
    description: 'Revoluciona las aplicaciones web con entrada de voz. Transcripci√≥n en tiempo real sin servidores.',
    whyTop: 'Soporte multiling√ºe, funciona offline. Habilita dictado, subt√≠tulos en vivo, comandos de voz.',
    useCases: ['Transcripci√≥n de audio', 'Subt√≠tulos en vivo', 'Comandos de voz', 'Dictado'],
    codeExample: `import { pipeline } from "@huggingface/transformers";

const transcriber = await pipeline(
  "automatic-speech-recognition",
  "onnx-community/whisper-tiny.en",
  { device: "webgpu" }
);

// Transcribir audio
const result = await transcriber(audioBlob);
console.log(result.text);`,
    modelId: 'onnx-community/whisper-tiny.en',
    docsUrl: 'https://huggingface.co/onnx-community/whisper-tiny.en',
    demoType: 'audio'
  },
  {
    id: 'qwen2-5',
    name: 'Qwen2.5-0.5B/1.5B-Instruct',
    rank: 4,
    category: 'llm',
    size: '500M - 1.5B par√°metros',
    vram: '944MB - 2GB',
    framework: 'WebLLM',
    innovationScore: 5,
    description: 'Mejor relaci√≥n calidad/tama√±o para chat en navegador. Los modelos peque√±os rivalizan con modelos 10x m√°s grandes.',
    whyTop: 'La familia Qwen2.5 ofrece la mejor calidad por par√°metro. Excelente para chatbots, asistentes, y cualquier tarea de texto que requiera inteligencia sin sacrificar velocidad.',
    useCases: ['Chatbots', 'Asistentes virtuales', 'Generaci√≥n de texto', 'Respuestas a preguntas'],
    codeExample: `import { CreateMLCEngine } from "@mlc-ai/web-llm";

const engine = await CreateMLCEngine(
  "Qwen2.5-1.5B-Instruct-q4f16_1-MLC",
  { initProgressCallback: (p) => console.log(p) }
);

const reply = await engine.chat.completions.create({
  messages: [{ role: "user", content: "Hola! Expl√≠came qu√© es WebGPU" }],
  stream: true
});`,
    modelId: 'Qwen2.5-1.5B-Instruct-q4f16_1-MLC',
    docsUrl: 'https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct',
    demoType: 'text'
  },
  {
    id: 'florence-2',
    name: 'Florence-2',
    rank: 5,
    category: 'vision',
    size: '232M par√°metros (base)',
    vram: '~500MB - 1GB',
    framework: 'Transformers.js',
    innovationScore: 5,
    description: 'La "navaja suiza" de la visi√≥n computacional en el navegador.',
    whyTop: 'Un solo modelo hace: OCR, detecci√≥n de objetos, segmentaci√≥n, captioning, visual Q&A. Perfecto para herramientas de accesibilidad y procesamiento de documentos.',
    useCases: ['OCR', 'Detecci√≥n de objetos', 'Segmentaci√≥n', 'Captioning', 'Visual Q&A'],
    codeExample: `import { Florence2ForConditionalGeneration } from "@huggingface/transformers";

const model = await Florence2ForConditionalGeneration.from_pretrained(
  "onnx-community/Florence-2-base-ft",
  {
    dtype: { vision_encoder: "fp16", encoder_model: "q4" },
    device: "webgpu"
  }
);

// M√∫ltiples tareas con el mismo modelo
const caption = await model.caption(image);
const objects = await model.detect(image);
const ocr = await model.ocr(image);`,
    modelId: 'onnx-community/Florence-2-base-ft',
    docsUrl: 'https://huggingface.co/onnx-community/Florence-2-base-ft',
    demoType: 'image'
  },
  {
    id: 'moondream2',
    name: 'Moondream2',
    rank: 6,
    category: 'multimodal',
    size: '~1.9B par√°metros',
    vram: '~2GB',
    framework: 'Transformers.js',
    innovationScore: 5,
    description: 'Especializado en tareas de visi√≥n √∫nicas: gaze tracking, UI understanding, OCR mejorado.',
    whyTop: 'Detecta hacia d√≥nde mira una persona, entiende interfaces de usuario (ideal para testing automatizado), OCR de documentos complejos. Output estructurado en JSON/XML.',
    useCases: ['Gaze tracking', 'UI Understanding', 'Testing automatizado', 'OCR avanzado'],
    codeExample: `import { Moondream } from "@huggingface/transformers";

const model = await Moondream.from_pretrained(
  "onnx-community/moondream2",
  { device: "webgpu" }
);

// Detecci√≥n de objetos
const objects = model.detect(image, "face")["objects"];

// Gaze detection - hacia d√≥nde mira la persona
const gaze = model.point(image, "person")["points"];

// OCR
const text = await model.ocr(image);`,
    modelId: 'onnx-community/moondream2',
    docsUrl: 'https://huggingface.co/vikhyatk/moondream2',
    demoType: 'multimodal'
  },
  {
    id: 'phi-3-mini',
    name: 'Phi-3/Phi-3.5-mini (4K/128K)',
    rank: 7,
    category: 'llm',
    size: '3.8B par√°metros',
    vram: '~2.1GB',
    framework: 'WebLLM',
    innovationScore: 5,
    description: 'Microsoft optimiz√≥ Phi para edge/browser. Calidad comparable a modelos 10x m√°s grandes.',
    whyTop: 'Contexto de 128K tokens permite procesar documentos largos. Excelente para RAG en el navegador.',
    useCases: ['Procesamiento de documentos', 'RAG', 'Contexto largo', 'Asistentes inteligentes'],
    codeExample: `import { CreateMLCEngine } from "@mlc-ai/web-llm";

const engine = await CreateMLCEngine(
  "Phi-3.5-mini-instruct-q4f16_1-MLC"
);

// Contexto largo - hasta 128K tokens
const reply = await engine.chat.completions.create({
  messages: [
    {
      role: "user",
      content: \`Analiza este documento largo: \${longDocument}\`
    }
  ]
});`,
    modelId: 'Phi-3.5-mini-instruct-q4f16_1-MLC',
    docsUrl: 'https://huggingface.co/microsoft/Phi-3.5-mini-instruct',
    demoType: 'text'
  },
  {
    id: 'sd-turbo',
    name: 'Stable Diffusion Turbo (ONNX)',
    rank: 8,
    category: 'generation',
    size: '~250MB - 1GB (quantizado)',
    vram: '~2-4GB',
    framework: 'ONNX Runtime Web',
    innovationScore: 5,
    description: 'Generaci√≥n de im√°genes directamente en el navegador sin servidores.',
    whyTop: 'Con quantizaci√≥n a 6/8 bits cabe en ~250MB. Permite apps de creatividad, dise√±o, y generaci√≥n de assets 100% privadas. Genera en <1 segundo.',
    useCases: ['Generaci√≥n de im√°genes', 'Dise√±o creativo', 'Assets de juegos', 'Arte digital'],
    codeExample: `import * as ort from 'onnxruntime-web/webgpu';

// Cargar modelo SD Turbo quantizado
const session = await ort.InferenceSession.create(
  'sd-turbo-q8.onnx',
  { executionProviders: ['webgpu'] }
);

// Generar imagen desde texto
const prompt = "A cyberpunk city at night, neon lights";
const result = await session.run({
  prompt: encodePrompt(prompt),
  steps: 1, // SD Turbo solo necesita 1 paso
  guidance_scale: 0
});`,
    modelId: 'stable-diffusion-turbo-onnx',
    docsUrl: 'https://huggingface.co/stabilityai/sd-turbo',
    demoType: 'image'
  },
  {
    id: 'llama-3-2',
    name: 'Llama-3.2-1B/3B-Instruct',
    rank: 9,
    category: 'llm',
    size: '1B / 3B par√°metros',
    vram: '~1.2GB / 2.9GB',
    framework: 'WebLLM',
    innovationScore: 5,
    description: 'Los modelos m√°s peque√±os de Llama 3.2 son perfectos para navegador.',
    whyTop: '128K tokens de contexto, excelente para seguir instrucciones, y la comunidad m√°s grande de fine-tunes. Licencia permisiva.',
    useCases: ['Chat general', 'Seguimiento de instrucciones', 'Fine-tuning', 'Asistentes'],
    codeExample: `import { CreateMLCEngine } from "@mlc-ai/web-llm";

const engine = await CreateMLCEngine(
  "Llama-3.2-1B-Instruct-q4f32_1-MLC"
);

const reply = await engine.chat.completions.create({
  messages: [
    { role: "system", content: "Eres un asistente √∫til." },
    { role: "user", content: "¬øQu√© es machine learning?" }
  ],
  max_tokens: 500,
  stream: true
});

// Stream de respuesta
for await (const chunk of reply) {
  console.log(chunk.choices[0].delta.content);
}`,
    modelId: 'Llama-3.2-1B-Instruct-q4f32_1-MLC',
    docsUrl: 'https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct',
    demoType: 'text'
  },
  {
    id: 'minithinky',
    name: 'MiniThinky-v2 (1B)',
    rank: 10,
    category: 'llm',
    size: '1B par√°metros',
    vram: '~1GB',
    framework: 'Transformers.js',
    innovationScore: 4,
    description: 'Optimizado espec√≠ficamente para inferencia en navegador. ~60 tokens/segundo.',
    whyTop: 'Puede realizar tareas de razonamiento y leer/manipular p√°ginas web, habilitando asistentes de navegador avanzados.',
    useCases: ['Asistentes de navegador', 'Razonamiento l√≥gico', 'Automatizaci√≥n web', 'Procesamiento r√°pido'],
    codeExample: `import { pipeline } from "@huggingface/transformers";

const generator = await pipeline(
  "text-generation",
  "onnx-community/MiniThinky-v2-1B",
  { device: "webgpu" }
);

const result = await generator(
  "Think step by step: If I have 3 apples and buy 5 more, how many do I have?",
  { max_new_tokens: 150 }
);`,
    modelId: 'onnx-community/MiniThinky-v2-1B',
    docsUrl: 'https://huggingface.co/onnx-community/MiniThinky-v2-1B',
    demoType: 'text'
  }
];

// Models 11-20 - Alta Innovaci√≥n
export const MODELS_11_20: ModelConfig[] = [
  {
    id: 'jina-embeddings',
    name: 'Jina-Embeddings-v2-base-en',
    rank: 11,
    category: 'embedding',
    size: '~137M par√°metros',
    vram: '~200MB',
    framework: 'Transformers.js',
    innovationScore: 4,
    description: 'Habilita b√∫squeda sem√°ntica sin servidores.',
    whyTop: 'Perfecto para crear sistemas RAG en el navegador donde los documentos nunca salen del dispositivo del usuario.',
    useCases: ['RAG', 'B√∫squeda sem√°ntica', 'Retrieval', 'Privacidad'],
    codeExample: `import { pipeline } from "@huggingface/transformers";

const extractor = await pipeline(
  'feature-extraction',
  'Xenova/jina-embeddings-v2-base-en',
  { dtype: "fp32" }
);

const embeddings = await extractor(
  ['texto para buscar'],
  { pooling: 'mean' }
);`,
    modelId: 'Xenova/jina-embeddings-v2-base-en',
    docsUrl: 'https://huggingface.co/Xenova/jina-embeddings-v2-base-en',
    demoType: 'embedding'
  },
  {
    id: 'nomic-embed',
    name: 'Nomic-Embed-Text-v1.5',
    rank: 12,
    category: 'embedding',
    size: '~137M par√°metros',
    vram: '~200MB',
    framework: 'Transformers.js',
    innovationScore: 4,
    description: 'Embeddings redimensionables (Matryoshka).',
    whyTop: 'Puedes elegir entre 64 y 768 dimensiones seg√∫n necesites velocidad vs calidad. Ideal para optimizar storage y b√∫squeda.',
    useCases: ['Embeddings flexibles', 'Optimizaci√≥n de storage', 'B√∫squeda eficiente', 'RAG'],
    codeExample: `import { pipeline } from "@huggingface/transformers";

const extractor = await pipeline(
  'feature-extraction',
  'Xenova/nomic-embed-text-v1.5'
);

// Elegir dimensiones: 64, 128, 256, 512, 768
const embeddings = await extractor(
  ['texto'],
  { pooling: 'mean', normalize: true }
);

// Reducir a 256 dimensiones
const reduced = embeddings[0].slice(0, 256);`,
    modelId: 'Xenova/nomic-embed-text-v1.5',
    docsUrl: 'https://huggingface.co/nomic-ai/nomic-embed-text-v1.5',
    demoType: 'embedding'
  },
  {
    id: 'all-minilm',
    name: 'All-MiniLM-L6-v2',
    rank: 13,
    category: 'embedding',
    size: '22M par√°metros',
    vram: '~50MB',
    framework: 'Transformers.js',
    innovationScore: 4,
    description: 'El modelo de embeddings m√°s ligero y r√°pido.',
    whyTop: 'Perfecto cuando necesitas b√∫squeda sem√°ntica pero con recursos m√≠nimos. Solo 384 dimensiones pero sorprendentemente efectivo.',
    useCases: ['Embeddings ultra-ligeros', 'Dispositivos limitados', 'B√∫squeda r√°pida', 'Clasificaci√≥n'],
    codeExample: `import { pipeline } from "@huggingface/transformers";

const extractor = await pipeline(
  'feature-extraction',
  'Xenova/all-MiniLM-L6-v2'
);

const embeddings = await extractor('texto', { pooling: 'mean' });
// Solo 384 dimensiones - muy eficiente`,
    modelId: 'Xenova/all-MiniLM-L6-v2',
    docsUrl: 'https://huggingface.co/Xenova/all-MiniLM-L6-v2',
    demoType: 'embedding'
  },
  {
    id: 'gemma-2-2b',
    name: 'Gemma-2-2b-it',
    rank: 14,
    category: 'llm',
    size: '2B par√°metros',
    vram: '~1.9GB',
    framework: 'WebLLM',
    innovationScore: 4,
    description: 'La tecnolog√≠a de Gemini de Google comprimida.',
    whyTop: 'Excelente seguimiento de instrucciones, multiling√ºe, y muy bien entrenado para ser seguro y √∫til.',
    useCases: ['Chat multiling√ºe', 'Instrucciones seguras', 'Asistentes', 'Traducci√≥n'],
    codeExample: `import { CreateMLCEngine } from "@mlc-ai/web-llm";

const engine = await CreateMLCEngine("gemma-2-2b-it-q4f16_1-MLC");

const reply = await engine.chat.completions.create({
  messages: [{ role: "user", content: "Explain quantum computing" }]
});`,
    modelId: 'gemma-2-2b-it-q4f16_1-MLC',
    docsUrl: 'https://huggingface.co/google/gemma-2-2b-it',
    demoType: 'text'
  },
  {
    id: 'sam',
    name: 'Segment Anything (SAM)',
    rank: 15,
    category: 'vision',
    size: 'Variable (encoder + decoder)',
    vram: '~1-2GB',
    framework: 'ONNX Runtime Web',
    innovationScore: 4,
    description: 'Segmentaci√≥n interactiva en el navegador.',
    whyTop: 'Meta\'s SAM permite a usuarios seleccionar y segmentar cualquier objeto en una imagen con clics. Revoluciona herramientas de edici√≥n de fotos. WebGPU acelera 19x vs CPU.',
    useCases: ['Edici√≥n de fotos', 'Selecci√≥n de objetos', 'Recorte inteligente', 'M√°scaras'],
    codeExample: `import * as ort from 'onnxruntime-web/webgpu';

// Cargar SAM encoder y decoder
const encoder = await ort.InferenceSession.create('sam_encoder.onnx');
const decoder = await ort.InferenceSession.create('sam_decoder.onnx');

// Codificar imagen una vez
const imageEmbed = await encoder.run({ image: imageData });

// Decodificar con puntos de click
const mask = await decoder.run({
  image_embeddings: imageEmbed,
  point_coords: [[x, y]], // Click del usuario
  point_labels: [1] // 1 = incluir, 0 = excluir
});`,
    modelId: 'segment-anything-onnx',
    docsUrl: 'https://segment-anything.com/',
    demoType: 'image'
  },
  {
    id: 'musicgen',
    name: 'MusicGen',
    rank: 16,
    category: 'generation',
    size: '300M - 1.5B par√°metros',
    vram: '~1-3GB',
    framework: 'Transformers.js',
    innovationScore: 4,
    description: 'Genera m√∫sica original basada en prompts de texto.',
    whyTop: 'Habilita aplicaciones de creatividad musical, generaci√≥n de soundtracks, y herramientas para creadores de contenido.',
    useCases: ['Generaci√≥n de m√∫sica', 'Soundtracks', 'Creatividad', 'Background music'],
    codeExample: `import { pipeline } from "@huggingface/transformers";

const musicGen = await pipeline(
  'text-to-audio',
  'Xenova/musicgen-small'
);

const audio = await musicGen(
  "upbeat electronic dance music with synths",
  { max_new_tokens: 500 }
);

// Reproducir audio generado
const audioBlob = new Blob([audio], { type: 'audio/wav' });
const audioUrl = URL.createObjectURL(audioBlob);`,
    modelId: 'Xenova/musicgen-small',
    docsUrl: 'https://huggingface.co/facebook/musicgen-small',
    demoType: 'audio'
  },
  {
    id: 'smollm2',
    name: 'SmolLM2-135M/360M',
    rank: 17,
    category: 'llm',
    size: '135M / 360M par√°metros',
    vram: '~300MB - 700MB',
    framework: 'WebLLM',
    innovationScore: 4,
    description: 'Incre√≠blemente peque√±o pero sorprendentemente capaz.',
    whyTop: 'Ideal para dispositivos con recursos muy limitados o cuando necesitas respuestas instant√°neas sin importar que sean menos sofisticadas.',
    useCases: ['Dispositivos limitados', 'Respuestas r√°pidas', 'IoT', 'Edge computing'],
    codeExample: `import { CreateMLCEngine } from "@mlc-ai/web-llm";

const engine = await CreateMLCEngine("SmolLM2-360M-Instruct-q4f16_1-MLC");

// Ultra r√°pido - ideal para autocompletado
const reply = await engine.chat.completions.create({
  messages: [{ role: "user", content: "Complete: The weather is" }],
  max_tokens: 20
});`,
    modelId: 'SmolLM2-360M-Instruct-q4f16_1-MLC',
    docsUrl: 'https://huggingface.co/HuggingFaceTB/SmolLM2-360M-Instruct',
    demoType: 'text'
  },
  {
    id: 'trocr',
    name: 'TrOCR',
    rank: 18,
    category: 'vision',
    size: '~334M par√°metros',
    vram: '~500MB',
    framework: 'Transformers.js',
    innovationScore: 4,
    description: 'Microsoft\'s transformer-based OCR.',
    whyTop: 'Superior a OCR tradicional especialmente para textos manuscritos y documentos complejos. Funciona completamente en el navegador.',
    useCases: ['OCR manuscrito', 'Documentos', 'Formularios', 'Digitalizaci√≥n'],
    codeExample: `import { pipeline } from "@huggingface/transformers";

const ocr = await pipeline(
  'image-to-text',
  'Xenova/trocr-base-handwritten'
);

// OCR de texto manuscrito
const result = await ocr(handwrittenImage);
console.log(result[0].generated_text);`,
    modelId: 'Xenova/trocr-base-handwritten',
    docsUrl: 'https://huggingface.co/microsoft/trocr-base-handwritten',
    demoType: 'image'
  },
  {
    id: 'depth-pro',
    name: 'Depth Pro',
    rank: 19,
    category: 'vision',
    size: '~300M par√°metros',
    vram: '~600MB',
    framework: 'Transformers.js',
    innovationScore: 4,
    description: 'Apple\'s modelo de estimaci√≥n de profundidad.',
    whyTop: 'Convierte cualquier imagen 2D en un mapa de profundidad 3D en <1 segundo. Habilita efectos de blur de retrato, AR sin sensores especiales.',
    useCases: ['Estimaci√≥n de profundidad', 'Blur de retrato', 'AR', 'Efectos 3D'],
    codeExample: `import { pipeline } from "@huggingface/transformers";

const depthEstimator = await pipeline(
  'depth-estimation',
  'Xenova/depth-pro',
  { device: "webgpu" }
);

const depth = await depthEstimator(image);
// depth.depth contiene el mapa de profundidad`,
    modelId: 'Xenova/depth-pro',
    docsUrl: 'https://huggingface.co/apple/depth-pro',
    demoType: 'image'
  },
  {
    id: 'detr',
    name: 'DETR / RT-DETR',
    rank: 20,
    category: 'vision',
    size: '41M - 100M par√°metros',
    vram: '~200MB - 500MB',
    framework: 'Transformers.js',
    innovationScore: 4,
    description: 'Detection Transformer de Facebook.',
    whyTop: 'Detecta y localiza objetos en im√°genes con bounding boxes. RT-DETR es la versi√≥n en tiempo real. Ideal para apps de inventario, seguridad, etc.',
    useCases: ['Detecci√≥n de objetos', 'Inventario', 'Seguridad', 'An√°lisis de im√°genes'],
    codeExample: `import { pipeline } from "@huggingface/transformers";

const detector = await pipeline(
  'object-detection',
  'Xenova/detr-resnet-50',
  { device: "webgpu" }
);

const objects = await detector(image);
// objects contiene: [{ label, score, box: {xmin, ymin, xmax, ymax} }]`,
    modelId: 'Xenova/detr-resnet-50',
    docsUrl: 'https://huggingface.co/facebook/detr-resnet-50',
    demoType: 'image'
  }
];

// Models 21-30 - High Innovation LLMs
export const MODELS_21_30: ModelConfig[] = [
  {
    id: 'hermes-3-llama',
    name: 'Hermes-3-Llama-3.2-3B',
    rank: 21,
    category: 'llm',
    size: '3B par√°metros',
    vram: '~2.9GB',
    framework: 'WebLLM',
    innovationScore: 4,
    description: 'Modelo optimizado para function calling y structured output.',
    whyTop: 'Excelente para crear agentes que necesitan llamar APIs, generar JSON estructurado, y seguir instrucciones complejas.',
    useCases: ['Function calling', 'JSON mode', 'Agentes AI', 'APIs'],
    codeExample: `import { CreateMLCEngine } from "@mlc-ai/web-llm";

const engine = await CreateMLCEngine("Hermes-3-Llama-3.2-3B-q4f16_1-MLC");

// Function calling
const tools = [{
  type: "function",
  function: {
    name: "get_weather",
    parameters: { type: "object", properties: { city: { type: "string" } } }
  }
}];

const reply = await engine.chat.completions.create({
  messages: [{ role: "user", content: "What's the weather in Madrid?" }],
  tools
});`,
    modelId: 'Hermes-3-Llama-3.2-3B-q4f16_1-MLC',
    docsUrl: 'https://huggingface.co/NousResearch/Hermes-3-Llama-3.2-3B',
    demoType: 'text'
  },
  {
    id: 'mistral-7b',
    name: 'Mistral-7B-v0.3',
    rank: 22,
    category: 'llm',
    size: '7B par√°metros',
    vram: '~5GB',
    framework: 'WebLLM',
    innovationScore: 4,
    description: 'Modelo general de alto rendimiento de Mistral AI.',
    whyTop: 'Balance perfecto entre calidad y velocidad. Requiere GPU potente pero ofrece respuestas de alta calidad para tareas generales.',
    useCases: ['Chat general', 'Escritura creativa', 'An√°lisis', 'Resumen'],
    codeExample: `import { CreateMLCEngine } from "@mlc-ai/web-llm";

const engine = await CreateMLCEngine("Mistral-7B-Instruct-v0.3-q4f16_1-MLC");

const reply = await engine.chat.completions.create({
  messages: [{ role: "user", content: "Write a haiku about coding" }],
  temperature: 0.7
});`,
    modelId: 'Mistral-7B-Instruct-v0.3-q4f16_1-MLC',
    docsUrl: 'https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3',
    demoType: 'text'
  },
  {
    id: 'qwen2-5-3b',
    name: 'Qwen2.5-3B-Instruct',
    rank: 23,
    category: 'llm',
    size: '3B par√°metros',
    vram: '~2.5GB',
    framework: 'WebLLM',
    innovationScore: 4,
    description: 'Modelo multiling√ºe con excelente soporte para chino e ingl√©s.',
    whyTop: 'El mejor modelo para aplicaciones multiling√ºes, especialmente chino. Calidad comparable a modelos m√°s grandes.',
    useCases: ['Multiling√ºe', 'Chino-Ingl√©s', 'Traducci√≥n', 'Chat'],
    codeExample: `import { CreateMLCEngine } from "@mlc-ai/web-llm";

const engine = await CreateMLCEngine("Qwen2.5-3B-Instruct-q4f16_1-MLC");

// Multiling√ºe
const reply = await engine.chat.completions.create({
  messages: [
    { role: "user", content: "Translate to Chinese: Hello, how are you?" }
  ]
});`,
    modelId: 'Qwen2.5-3B-Instruct-q4f16_1-MLC',
    docsUrl: 'https://huggingface.co/Qwen/Qwen2.5-3B-Instruct',
    demoType: 'text'
  },
  {
    id: 'phi-4-mini',
    name: 'Phi-4-mini-reasoning',
    rank: 24,
    category: 'llm',
    size: '3.8B par√°metros',
    vram: '~2GB',
    framework: 'Transformers.js',
    innovationScore: 4,
    description: 'Modelo de razonamiento sint√©tico de Microsoft.',
    whyTop: 'Entrenado con datos sint√©ticos de alta calidad para tareas de razonamiento. Excelente para matem√°ticas y l√≥gica.',
    useCases: ['Razonamiento', 'Matem√°ticas', 'L√≥gica', 'Problemas'],
    codeExample: `import { pipeline } from "@huggingface/transformers";

const generator = await pipeline(
  "text-generation",
  "onnx-community/Phi-4-mini-reasoning",
  { device: "webgpu" }
);

const result = await generator(
  "Solve: A train travels 120km in 2 hours. What is its speed?",
  { max_new_tokens: 200 }
);`,
    modelId: 'onnx-community/Phi-4-mini-reasoning',
    docsUrl: 'https://huggingface.co/microsoft/Phi-4-mini-instruct',
    demoType: 'text'
  },
  {
    id: 'deepseek-r1-llama-8b',
    name: 'DeepSeek-R1-Distill-Llama-8B',
    rank: 25,
    category: 'llm',
    size: '8B par√°metros',
    vram: '~5-6GB',
    framework: 'WebLLM',
    innovationScore: 4,
    description: 'Versi√≥n m√°s grande del modelo de razonamiento DeepSeek.',
    whyTop: 'Razonamiento avanzado con mayor capacidad. Requiere GPU potente pero ofrece pensamiento m√°s profundo.',
    useCases: ['Razonamiento complejo', 'An√°lisis', 'Problemas dif√≠ciles', 'C√≥digo'],
    codeExample: `import { CreateMLCEngine } from "@mlc-ai/web-llm";

const engine = await CreateMLCEngine("DeepSeek-R1-Distill-Llama-8B-q4f16_1-MLC");

const reply = await engine.chat.completions.create({
  messages: [{
    role: "user",
    content: "Think step by step: If 5 machines can make 5 widgets in 5 minutes..."
  }]
});`,
    modelId: 'DeepSeek-R1-Distill-Llama-8B-q4f16_1-MLC',
    docsUrl: 'https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B',
    demoType: 'text'
  },
  {
    id: 'hermes-2-pro',
    name: 'Hermes-2-Pro-Llama-3-8B',
    rank: 26,
    category: 'llm',
    size: '8B par√°metros',
    vram: '~5GB',
    framework: 'WebLLM',
    innovationScore: 4,
    description: 'Modelo avanzado para tool use y agentes.',
    whyTop: 'Especializado en uso de herramientas con formato estructurado. Ideal para construir agentes AI complejos.',
    useCases: ['Tool use', 'Agentes', 'Automatizaci√≥n', 'Multi-step tasks'],
    codeExample: `import { CreateMLCEngine } from "@mlc-ai/web-llm";

const engine = await CreateMLCEngine("Hermes-2-Pro-Llama-3-8B-q4f16_1-MLC");

// Tool use avanzado
const reply = await engine.chat.completions.create({
  messages: [{ role: "user", content: "Search for flights and book the cheapest one" }],
  tools: [/* flight tools definition */]
});`,
    modelId: 'Hermes-2-Pro-Llama-3-8B-q4f16_1-MLC',
    docsUrl: 'https://huggingface.co/NousResearch/Hermes-2-Pro-Llama-3-8B',
    demoType: 'text'
  },
  {
    id: 'neuralhermes',
    name: 'NeuralHermes-2.5-Mistral-7B',
    rank: 27,
    category: 'llm',
    size: '7B par√°metros',
    vram: '~5GB',
    framework: 'WebLLM',
    innovationScore: 3,
    description: 'Fine-tune creativo de Mistral para escritura.',
    whyTop: 'Optimizado para generaci√≥n creativa y storytelling. Excelente para escritura de ficci√≥n y contenido.',
    useCases: ['Escritura creativa', 'Storytelling', 'Ficci√≥n', 'Contenido'],
    codeExample: `import { CreateMLCEngine } from "@mlc-ai/web-llm";

const engine = await CreateMLCEngine("NeuralHermes-2.5-Mistral-7B-q4f16_1-MLC");

const reply = await engine.chat.completions.create({
  messages: [{
    role: "user",
    content: "Write a short story about a robot learning to paint"
  }],
  temperature: 0.9
});`,
    modelId: 'NeuralHermes-2.5-Mistral-7B-q4f16_1-MLC',
    docsUrl: 'https://huggingface.co/mlabonne/NeuralHermes-2.5-Mistral-7B',
    demoType: 'text'
  },
  {
    id: 'openhermes',
    name: 'OpenHermes-2.5-Mistral-7B',
    rank: 28,
    category: 'llm',
    size: '7B par√°metros',
    vram: '~5GB',
    framework: 'WebLLM',
    innovationScore: 3,
    description: 'Modelo general entrenado con datos curados.',
    whyTop: 'Entrenado con dataset curado de alta calidad. Bueno para instrucciones generales y tareas variadas.',
    useCases: ['Instrucciones', 'General purpose', 'Q&A', 'Asistente'],
    codeExample: `import { CreateMLCEngine } from "@mlc-ai/web-llm";

const engine = await CreateMLCEngine("OpenHermes-2.5-Mistral-7B-q4f16_1-MLC");

const reply = await engine.chat.completions.create({
  messages: [{ role: "user", content: "Explain photosynthesis simply" }]
});`,
    modelId: 'OpenHermes-2.5-Mistral-7B-q4f16_1-MLC',
    docsUrl: 'https://huggingface.co/teknium/OpenHermes-2.5-Mistral-7B',
    demoType: 'text'
  },
  {
    id: 'gemma-2-9b',
    name: 'Gemma-2-9b-it',
    rank: 29,
    category: 'llm',
    size: '9B par√°metros',
    vram: '~6.4GB',
    framework: 'WebLLM',
    innovationScore: 4,
    description: 'Modelo grande de Google con calidad Gemini.',
    whyTop: 'La mejor calidad de la familia Gemma. Requiere m√°s VRAM pero ofrece respuestas m√°s sofisticadas.',
    useCases: ['Alta calidad', 'An√°lisis complejo', 'Escritura', 'Razonamiento'],
    codeExample: `import { CreateMLCEngine } from "@mlc-ai/web-llm";

const engine = await CreateMLCEngine("gemma-2-9b-it-q4f16_1-MLC");

const reply = await engine.chat.completions.create({
  messages: [{
    role: "user",
    content: "Analyze the pros and cons of remote work"
  }]
});`,
    modelId: 'gemma-2-9b-it-q4f16_1-MLC',
    docsUrl: 'https://huggingface.co/google/gemma-2-9b-it',
    demoType: 'text'
  },
  {
    id: 'llama-3-1-8b',
    name: 'Llama-3.1-8B-Instruct',
    rank: 30,
    category: 'llm',
    size: '8B par√°metros',
    vram: '~5GB',
    framework: 'WebLLM',
    innovationScore: 4,
    description: 'Modelo con contexto 128K y tool use nativo.',
    whyTop: 'Contexto ultra largo de 128K tokens. Ideal para RAG con documentos extensos y conversaciones largas.',
    useCases: ['Contexto largo', 'RAG', 'Documentos', 'Tool use'],
    codeExample: `import { CreateMLCEngine } from "@mlc-ai/web-llm";

const engine = await CreateMLCEngine("Llama-3.1-8B-Instruct-q4f16_1-MLC");

// Contexto largo - hasta 128K tokens
const reply = await engine.chat.completions.create({
  messages: [{
    role: "user",
    content: \`Summarize this long document: \${longDocument}\`
  }]
});`,
    modelId: 'Llama-3.1-8B-Instruct-q4f16_1-MLC',
    docsUrl: 'https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct',
    demoType: 'text'
  }
];

// Models 31-40 - Vision Models
export const MODELS_31_40: ModelConfig[] = [
  {
    id: 'clip',
    name: 'CLIP (OpenAI)',
    rank: 31,
    category: 'multimodal',
    size: '428M par√°metros',
    vram: '~500MB',
    framework: 'Transformers.js',
    innovationScore: 4,
    description: 'Embeddings imagen-texto de OpenAI.',
    whyTop: 'Revolucion√≥ la conexi√≥n entre im√°genes y texto. Permite b√∫squeda de im√°genes por texto y clasificaci√≥n zero-shot.',
    useCases: ['Image search', 'Zero-shot classification', 'Embeddings multimodal', 'Similarity'],
    codeExample: `import { pipeline } from "@huggingface/transformers";

const classifier = await pipeline(
  "zero-shot-image-classification",
  "Xenova/clip-vit-base-patch32"
);

const result = await classifier(image, ["a cat", "a dog", "a bird"]);
// Returns probabilities for each label`,
    modelId: 'Xenova/clip-vit-base-patch32',
    docsUrl: 'https://huggingface.co/openai/clip-vit-base-patch32',
    demoType: 'multimodal'
  },
  {
    id: 'siglip',
    name: 'SigLIP',
    rank: 32,
    category: 'multimodal',
    size: '400M par√°metros',
    vram: '~500MB',
    framework: 'Transformers.js',
    innovationScore: 4,
    description: 'Versi√≥n mejorada de CLIP por Google.',
    whyTop: 'Mejor que CLIP original en tareas de clasificaci√≥n y retrieval. Funci√≥n sigmoid en lugar de softmax.',
    useCases: ['Image classification', 'Retrieval mejorado', 'Zero-shot', 'Fine-tuning'],
    codeExample: `import { pipeline } from "@huggingface/transformers";

const classifier = await pipeline(
  "zero-shot-image-classification",
  "Xenova/siglip-base-patch16-224"
);

const result = await classifier(image, ["photo", "drawing", "painting"]);`,
    modelId: 'Xenova/siglip-base-patch16-224',
    docsUrl: 'https://huggingface.co/google/siglip-base-patch16-224',
    demoType: 'multimodal'
  },
  {
    id: 'dinov2',
    name: 'DINOv2',
    rank: 33,
    category: 'vision',
    size: '300M par√°metros',
    vram: '~400MB',
    framework: 'Transformers.js',
    innovationScore: 4,
    description: 'Feature extraction visual self-supervised de Meta.',
    whyTop: 'Extrae features visuales universales sin necesidad de texto. Ideal para clustering de im√°genes y similitud visual.',
    useCases: ['Feature extraction', 'Image clustering', 'Visual similarity', 'Transfer learning'],
    codeExample: `import { pipeline } from "@huggingface/transformers";

const extractor = await pipeline(
  "image-feature-extraction",
  "Xenova/dinov2-small"
);

const features = await extractor(image);
// 384-dimensional feature vector`,
    modelId: 'Xenova/dinov2-small',
    docsUrl: 'https://huggingface.co/facebook/dinov2-small',
    demoType: 'image'
  },
  {
    id: 'qwen2-vl-2b',
    name: 'Qwen2-VL-2B',
    rank: 34,
    category: 'multimodal',
    size: '2B par√°metros',
    vram: '~2GB',
    framework: 'Transformers.js',
    innovationScore: 4,
    description: 'Modelo vision-language multiling√ºe de Alibaba.',
    whyTop: 'VQA multiling√ºe con soporte nativo para chino. Entiende im√°genes y responde preguntas en m√∫ltiples idiomas.',
    useCases: ['VQA multiling√ºe', 'Descripci√≥n de im√°genes', 'OCR', 'An√°lisis visual'],
    codeExample: `import { Qwen2VLForConditionalGeneration } from "@huggingface/transformers";

const model = await Qwen2VLForConditionalGeneration.from_pretrained(
  "onnx-community/Qwen2-VL-2B-Instruct",
  { device: "webgpu" }
);

const result = await model.generate({
  image: imageElement,
  prompt: "Describe esta imagen en espa√±ol"
});`,
    modelId: 'onnx-community/Qwen2-VL-2B-Instruct',
    docsUrl: 'https://huggingface.co/Qwen/Qwen2-VL-2B-Instruct',
    demoType: 'multimodal'
  },
  {
    id: 'llava',
    name: 'LLaVA',
    rank: 35,
    category: 'multimodal',
    size: '7B+ par√°metros',
    vram: '~5GB+',
    framework: 'WebLLM',
    innovationScore: 4,
    description: 'Vision-language model completo con capacidad de chat.',
    whyTop: 'Combina visi√≥n y lenguaje para conversaciones sobre im√°genes. Requiere GPU potente pero muy capaz.',
    useCases: ['Visual chat', 'Image understanding', 'Multi-turn VQA', 'Analysis'],
    codeExample: `import { CreateMLCEngine } from "@mlc-ai/web-llm";

const engine = await CreateMLCEngine("llava-1.5-7b-q4f16_1-MLC");

const reply = await engine.chat.completions.create({
  messages: [{
    role: "user",
    content: [
      { type: "image", image: imageBase64 },
      { type: "text", text: "What's happening in this image?" }
    ]
  }]
});`,
    modelId: 'llava-1.5-7b-q4f16_1-MLC',
    docsUrl: 'https://llava-vl.github.io/',
    demoType: 'multimodal'
  },
  {
    id: 'mobilenetv4',
    name: 'MobileNetV4',
    rank: 36,
    category: 'vision',
    size: '6M par√°metros',
    vram: '~50MB',
    framework: 'Transformers.js',
    innovationScore: 3,
    description: 'Clasificaci√≥n de im√°genes ultra-r√°pida.',
    whyTop: 'El modelo m√°s r√°pido para clasificaci√≥n. Ideal para aplicaciones m√≥viles y en tiempo real.',
    useCases: ['Clasificaci√≥n r√°pida', 'Mobile apps', 'Real-time', 'Edge devices'],
    codeExample: `import { pipeline } from "@huggingface/transformers";

const classifier = await pipeline(
  "image-classification",
  "onnx-community/mobilenetv4_conv_small.e2400_r224_in1k",
  { device: "webgpu" }
);

const result = await classifier(image);
// [{ label: "cat", score: 0.95 }, ...]`,
    modelId: 'onnx-community/mobilenetv4_conv_small.e2400_r224_in1k',
    docsUrl: 'https://huggingface.co/timm/mobilenetv4_conv_small.e2400_r224_in1k',
    demoType: 'image'
  },
  {
    id: 'efficientnet',
    name: 'EfficientNet',
    rank: 37,
    category: 'vision',
    size: '5-66M par√°metros',
    vram: '~50-200MB',
    framework: 'Transformers.js',
    innovationScore: 3,
    description: 'Clasificaci√≥n eficiente con buen balance.',
    whyTop: 'Familia de modelos con diferentes tama√±os. Elige seg√∫n tus recursos: B0 para velocidad, B7 para precisi√≥n.',
    useCases: ['Clasificaci√≥n eficiente', 'Scalable', 'Production', 'Fine-tuning'],
    codeExample: `import { pipeline } from "@huggingface/transformers";

const classifier = await pipeline(
  "image-classification",
  "Xenova/efficientnet-b0"
);

const result = await classifier(image);`,
    modelId: 'Xenova/efficientnet-b0',
    docsUrl: 'https://huggingface.co/google/efficientnet-b0',
    demoType: 'image'
  },
  {
    id: 'vit',
    name: 'ViT (Vision Transformer)',
    rank: 38,
    category: 'vision',
    size: '86M par√°metros',
    vram: '~200MB',
    framework: 'Transformers.js',
    innovationScore: 3,
    description: 'El transformer original para visi√≥n.',
    whyTop: 'Pionero en aplicar transformers a im√°genes. Buen baseline para muchas tareas de visi√≥n.',
    useCases: ['Clasificaci√≥n base', 'Transfer learning', 'Feature extraction', 'Fine-tuning'],
    codeExample: `import { pipeline } from "@huggingface/transformers";

const classifier = await pipeline(
  "image-classification",
  "Xenova/vit-base-patch16-224"
);

const result = await classifier(image);`,
    modelId: 'Xenova/vit-base-patch16-224',
    docsUrl: 'https://huggingface.co/google/vit-base-patch16-224',
    demoType: 'image'
  },
  {
    id: 'fastvit',
    name: 'FastViT',
    rank: 39,
    category: 'vision',
    size: '50M par√°metros',
    vram: '~100MB',
    framework: 'Transformers.js',
    innovationScore: 3,
    description: 'ViT optimizado para velocidad.',
    whyTop: 'Combina la calidad de ViT con velocidad de MobileNet. Buen compromiso para producci√≥n.',
    useCases: ['Fast inference', 'Production', 'Mobile', 'Real-time'],
    codeExample: `import { pipeline } from "@huggingface/transformers";

const classifier = await pipeline(
  "image-classification",
  "Xenova/fastvit-t8"
);

const result = await classifier(image);`,
    modelId: 'Xenova/fastvit-t8',
    docsUrl: 'https://huggingface.co/apple/fastvit-t8',
    demoType: 'image'
  },
  {
    id: 'hiera',
    name: 'Hiera',
    rank: 40,
    category: 'vision',
    size: '100M par√°metros',
    vram: '~200MB',
    framework: 'Transformers.js',
    innovationScore: 3,
    description: 'Visi√≥n jer√°rquica de Meta.',
    whyTop: 'Procesa im√°genes de forma jer√°rquica para mejor eficiencia. Bueno para m√∫ltiples escalas.',
    useCases: ['Multi-scale vision', 'Hierarchical features', 'Efficient processing', 'Research'],
    codeExample: `import { pipeline } from "@huggingface/transformers";

const classifier = await pipeline(
  "image-classification",
  "Xenova/hiera-small-224"
);

const result = await classifier(image);`,
    modelId: 'Xenova/hiera-small-224',
    docsUrl: 'https://huggingface.co/facebook/hiera-small-224',
    demoType: 'image'
  }
];

// All models combined for easy access
export const ALL_MODELS: ModelConfig[] = [...TOP_10_MODELS, ...MODELS_11_20, ...MODELS_21_30, ...MODELS_31_40];

// Category metadata
export const MODEL_CATEGORIES: Record<ModelCategory, { label: string; icon: string; color: string }> = {
  'llm': { label: 'Language Model', icon: 'üß†', color: '#00ff44' },
  'vision': { label: 'Vision', icon: 'üëÅÔ∏è', color: '#00aaff' },
  'audio': { label: 'Audio', icon: 'üé§', color: '#ff6600' },
  'embedding': { label: 'Embedding', icon: 'üîç', color: '#aa00ff' },
  'multimodal': { label: 'Multimodal', icon: 'üåê', color: '#ffaa00' },
  'generation': { label: 'Generation', icon: 'üé®', color: '#ff00aa' }
};

// Framework metadata
export const FRAMEWORKS: Record<ModelFramework, { label: string; description: string; url: string }> = {
  'WebLLM': {
    label: 'WebLLM (MLC-AI)',
    description: 'Framework optimizado para LLMs con WebGPU. Soporta streaming y contexto largo.',
    url: 'https://github.com/mlc-ai/web-llm'
  },
  'Transformers.js': {
    label: 'Transformers.js (HuggingFace)',
    description: 'Port de Transformers de Python. Soporta 100+ arquitecturas y tareas.',
    url: 'https://github.com/huggingface/transformers.js'
  },
  'ONNX Runtime Web': {
    label: 'ONNX Runtime Web',
    description: 'Runtime de Microsoft para modelos ONNX. Ideal para modelos custom.',
    url: 'https://onnxruntime.ai/docs/get-started/with-javascript/web.html'
  }
};
